{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AB_data.ipynb","private_outputs":true,"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ODs3txTZeNwe"},"source":["# !pip uninstall tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKE6XlUe1zaZ"},"source":["# !pip uninstall keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mAcziMv52CHW"},"source":["# !pip install tensorflow==1.14"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Np0eIfv2LdH"},"source":["# !pip install keras==2.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsXWIs8R2T5y"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkhFn2FY2bUY"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedShuffleSplit\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten, Convolution1D, Dropout, MaxPooling1D\n","from keras.optimizers import SGD\n","from keras.utils import np_utils\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VxQmDkD9R60"},"source":["train = pd.read_csv('/gdrive/MyDrive/데이터2/TRAIN_AB.csv')\n","test = pd.read_csv('/gdrive/MyDrive/데이터2/TEST_AB.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwA54SAh9tqO"},"source":["def encode(train, test):\n","    label_encoder = LabelEncoder().fit(train.activity)\n","    labels = label_encoder.transform(train.activity)\n","    test_labels = label_encoder.transform(test.activity)\n","    classes = list(label_encoder.classes_)\n","\n","    train = train.drop(['activity'], axis=1)\n","    test = test.drop('activity', axis=1)\n","\n","    return train, labels, test, test_labels,classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVluQM0O-AUl"},"source":["#train : label이 제거되고 데이터만 남은 train dataset\n","#test : label이 제거되고 데이터만 남은 test dataset\n","#labels : 숫자라벨링 y값으로 사용할 것들 0,1,2,3\n","#classes : activity 항목들 ['Badminton', 'Running', 'Standing', 'Walking']\n","train, labels, test, test_labels, classes = encode(train, test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fi6ZeZ4d-mS3"},"source":["# standardize train features\n","scaler = StandardScaler().fit(train.values)\n","scaled_train = scaler.transform(train.values)\n","scaled_test = scaler.transform(test.values)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtDIwcPKJDGb"},"source":["scaled_train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9OywK505IGjI"},"source":[""]},{"cell_type":"code","metadata":{"id":"2ricLAsE-onH"},"source":["# split train data into train and validation\n","sss = StratifiedShuffleSplit(test_size=0.1, random_state=23)\n","for train_index, valid_index in sss.split(scaled_train, labels):\n","    X_train, X_valid = scaled_train[train_index], scaled_train[valid_index]\n","    y_train, y_valid = labels[train_index], labels[valid_index]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iWhURls-xZB"},"source":["nb_features = 100 # number of features per features type (shape, texture, margin)   \n","nb_class = len(classes)\n","\n","\n","# reshape train data\n","X_train_r = np.zeros((len(X_train), nb_features, 6))\n","X_train_r[:, :, 0] = X_train[:, 0:nb_features]\n","X_train_r[:, :, 1] = X_train[:, nb_features:200]\n","X_train_r[:, :, 2] = X_train[:, 200:300]\n","X_train_r[:, :, 0] = X_train[:, 300:400]\n","X_train_r[:, :, 1] = X_train[:, 400:500]\n","X_train_r[:, :, 2] = X_train[:, 500:]\n","\n","# reshape validation data\n","X_valid_r = np.zeros((len(X_valid), nb_features, 6))\n","X_valid_r[:, :, 0] = X_valid[:, :nb_features]\n","X_valid_r[:, :, 1] = X_valid[:, nb_features:200]\n","X_valid_r[:, :, 2] = X_valid[:, 200:300]\n","X_valid_r[:, :, 0] = X_valid[:, 300:400]\n","X_valid_r[:, :, 1] = X_valid[:, 400:500]\n","X_valid_r[:, :, 2] = X_valid[:, 500:]\n","\n","\n","# reshape validation data\n","X_test_r = np.zeros((len(scaled_test), nb_features, 6))\n","X_test_r[:, :, 0] = scaled_test[:, :nb_features]\n","X_test_r[:, :, 1] = scaled_test[:, nb_features:200]\n","X_test_r[:, :, 2] = scaled_test[:, 200:300]\n","X_test_r[:, :, 0] = scaled_test[:, 300:400]\n","X_test_r[:, :, 1] = scaled_test[:, 400:500]\n","X_test_r[:, :, 2] = scaled_test[:, 500:]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A04gCGyGZRKt"},"source":["X_test_r"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXLiiwyS_ZVH"},"source":["# Keras model with one Convolution1D layer\n","# unfortunately more number of covnolutional layers, filters and filters lenght \n","# don't give better accuracy\n","model = Sequential()\n","model.add(Convolution1D(nb_filter=32, filter_length=10, input_shape=(nb_features, 6)))\n","model.add(MaxPooling1D(pool_size=2, strides=None, padding='same'))\n","model.add(Convolution1D(nb_filter=32, filter_length=10, input_shape=(nb_features, 6)))\n","model.add(MaxPooling1D(pool_size=2, strides=None, padding='same'))\n","model.add(Activation('relu'))\n","model.add(Flatten())\n","model.add(Dropout(0.4))\n","model.add(Dense(2048, activation='relu'))\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dense(nb_class))\n","model.add(Activation('softmax'))\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzadMwosAGg5"},"source":["y_train = np_utils.to_categorical(y_train, nb_class)\n","y_valid = np_utils.to_categorical(y_valid, nb_class)\n","test_labels = np_utils.to_categorical(test_labels, nb_class)\n","\n","sgd = SGD(lr=0.01, nesterov=True, decay=1e-6, momentum=0.9)\n","model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n","\n","nb_epoch = 15\n","#model.fit(X_train_r, y_train, nb_epoch=nb_epoch, validation_data=(X_valid_r, y_valid), batch_size=16)\n","start = time.time()\n","mhistory = model.fit(X_train_r, y_train, epochs=nb_epoch,validation_data=(X_valid_r, y_valid), batch_size=16)\n","print(\"time : \", time.time()-start)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tofK-XfJAL23"},"source":["# 모델 평가\n","print('\\n-- Evalutate --')\n","scores = model.evaluate(X_test_r, test_labels, verbose=1)\n","\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYtoTT6RAWH_"},"source":["import matplotlib.pyplot as plt\n","\n","# 모델 저장\n","#model.save('/gdrive/MyDrive/데이터2/모델저장/AB/model20_5.h5')\n","\n","# 학습과정 그래프\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(mhistory.history['loss'], 'y', label='train loss')\n","loss_ax.plot(mhistory.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([-0.2, 1.2])\n","\n","acc_ax.plot(mhistory.history['acc'], 'b', label='train acc')\n","acc_ax.plot(mhistory.history['val_acc'], 'g', label='val acc')\n","\n","acc_ax.set_ylim([-0.2, 1.2])\n","\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuracy')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","fig = plt.gcf()\n","plt.show()\n","fig.savefig('/gdrive/MyDrive/데이터2/모델그래프/AB/model30_5.png', bbox_inches='tight')\n"],"execution_count":null,"outputs":[]}]}